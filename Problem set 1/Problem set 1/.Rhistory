testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 3,
gamma = 1,
coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 3,
gamma = 1,
coef0 = 1
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 3,
gamma = 1,
coef0 = .1
)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 3,
gamma = 1,
coef0 = .1
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 3,
gamma = 1,
coef0 = 2
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 4,
gamma = 1,
coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 4,
gamma = 1,
coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'polynomial',
degree = 3,
gamma =.1,
coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
acc
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'radial',
degree = 3,
gamma =.1,
#coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'radial',
degree = 3,
gamma =.1
#coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'radial',
#degree = 3,
gamma =.01
#coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'radial',
#degree = 3,
gamma =.001
#coef0 = 0
)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'radial',
#degree = 3,
gamma =.001
#coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'radial',
#degree = 3,
gamma =.01
#coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
acc
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'sigmoid',
#degree = 3,
gamma =.01
coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'sigmoid',
#degree = 3,
gamma =.01,
coef0 = 0
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'sigmoid',
#degree = 3,
gamma =.01,
coef0 = 1
)
y_pred = predict(classifier, newdata = testData[-9])
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'sigmoid',
#degree = 3,
gamma =.01,
coef0 = 1
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'sigmoid',
#degree = 3,
gamma =.01,
coef0 = 2
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
#Perform 10 fold cross validation
for(i in 1:10){
#Segement your data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testIndexes
testData <- mydata[testIndexes, ]
trainData <- mydata[-testIndexes, ]
#Use the test and train data partitions however you desire...
classifier = svm(formula = class ~ .,
data = trainData,
type = 'C-classification',
scale = FALSE,
kernel = 'sigmoid',
#degree = 3,
gamma =.01,
coef0 = 1
)
y_pred = predict(classifier, newdata = testData[-9])
cm = table(testData[, 9], y_pred)
accuracy_Train <- sum(diag(cm)) / sum(cm)
acc[i] <- accuracy_Train
}
mean(acc)
acc
x<-c(1,3,9,9,11,13,13,15, 15,16, 17, 30)
boxplot(x)
boxplot.stats(X)
boxplot.stats(x)
iqr<-IQR(x)
IQR(x)
#clear the environment
rm(list=ls())
library(tidyverse)
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#Import the data
mydata = read.csv("pima-indians-diabetes.csv", header = FALSE)
names(mydata) <- c( "V0","V1","V2","V3","V4","V5","V6","V7","V8")
glimpse(mydata)
names(mydata) <- c( "V1","V2","V3","V4","V5","V6","V7","V8","V9")
#Separating group 2 and cleaning 0's by replacing mean
column2 =  mydata$V2[]
#Separating group 4 and cleaning 0's by replacing mean
column4 =  mydata$V4[]
#Separate data by class label for column 2
tempdata1 <- split(mydata$V2, mydata$V9==1)
column2group1 = as.numeric(unlist(tempdata1[1]))
column2group2 = as.numeric(unlist(tempdata1[2]))
#Separate data by class label  for column 4
tempdata2 <- split(mydata$V4, mydata$V9==1)
column4group1 = as.numeric(unlist(tempdata2[1]))
column4group2 = as.numeric(unlist(tempdata2[2]))
hist(column2)
mean(column2)
getmode(column2)
median(column2)
sd(column2)
max(column2)
min(column2)
hist(column2group1)
mean(column2group1)
#Separating group 2 and cleaning 0's by replacing mean
attribute_2 =  mydata$V2[]
#Separating group 4 and cleaning 0's by replacing mean
attribute_4 =  mydata$V4[]
#Separate data by class label for column 2
tempdata1 <- split(mydata$V2, mydata$V9==1)
attribute_2_class_1 = as.numeric(unlist(tempdata1[1]))
attribute_2_class_2 = as.numeric(unlist(tempdata1[2]))
#Separate data by class label  for column 4
tempdata2 <- split(mydata$V4, mydata$V9==1)
attribute_4_class_1 = as.numeric(unlist(tempdata2[1]))
attribute_4_class_2 = as.numeric(unlist(tempdata2[2]))
hist(attribute_2)
mean(attribute_2)
getmode(attribute_2)
median(attribute_2)
sd(attribute_2)
max(attribute_2)
min(attribute_2)
hist(attribute_2_class_1)
mean(attribute_2_class_1)
getmode(attribute_2_class_1)
median(attribute_2_class_1)
sd(attribute_2_class_1)
max(attribute_2_class_1)
min(attribute_2_class_1)
hist(attribute_2_class_2)
mean(attribute_2_class_2)
getmode(attribute_2_class_2)
median(attribute_2_class_2)
sd(attribute_2_class_2)
max(attribute_2_class_2)
min(attribute_2_class_2)
hist(attribute_4)
mean(attribute_4)
getmode(attribute_4)
median(attribute_4)
sd(attribute_4)
max(attribute_4)
min(attribute_4)
hist(attribute_4_class_1)
mean(attribute_4_class_1)
getmode(attribute_4_class_1)
median(attribute_4_class_1)
sd(attribute_4_class_1)
max(attribute_4_class_1)
min(attribute_4_class_1)
hist(attribute_4_class_2)
mean(attribute_4_class_2)
getmode(attribute_4_class_2)
median(attribute_4_class_2)
sd(attribute_4_class_2)
max(attribute_4_class_2)
min(attribute_4_class_2)
par(mfrow=c(1,3))
hist(attribute_2)
hist(attribute_2_class_1)
hist(attribute_2_class_2)
par(mfrow=c(1,3))
hist(attribute_4)
hist(attribute_4_class_1)
hist(attribute_4_class_2)
par(mfrow=c(1,2))
hist(attribute_2)
hist(attribute_4)
